{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some work with Image APIs\n",
    "\n",
    "So far, we have spent time looking at the ways in which \"unstructured data\" like text might be broken into a series of descriptors -- from \"likes\" to words in a post to the sentiment or some other characterization of a sentence. We now move up one level in complexity and consider images. \n",
    "<br><br>\n",
    "\n",
    "<img src=\"https://github.com/computationaljournalism/columbia2018/raw/master/images/abc.jpg\" style=\"width: 65%; border: #000000 1px outset;\">\n",
    "<br><br>\n",
    "\n",
    "Recall that we can display images in the Jupyter notebook using a class `Image` from the `IPython` package. Here we look at three pictures of, well, my dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url1 = \"https://github.com/computationaljournalism/columbia2018/raw/master/images/IMG_0254.jpg\"\n",
    "url2 = \"https://github.com/computationaljournalism/columbia2018/raw/master/images/IMG_4627.jpg\"\n",
    "url3 = \"https://github.com/computationaljournalism/columbia2018/raw/master/images/IMG_3781.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=url1,width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see when you look at this image? A sign that, for a moment at least, spring had arrived in NYC? The stoic look of my dog? The fact that her leash leads back to me, the person forcing her to hold still for the camera? Maybe you see the dry leaves or the barren tree limbs -- soul-crushing reminders of a winter that won't let go... but I digress.\n",
    "\n",
    "Let's try out some tools for pulling information from images. We will use a commodity API from [Google called Cloud Vision](https://cloud.google.com/vision). To use it, we need to update an obscure package I won't spend time on and then install the `google-cloud-vision` package.\n",
    "<br><br>\n",
    "\n",
    "<img src=\"https://github.com/computationaljournalism/columbia2018/raw/master/images/cv.jpg\" style=\"width: 75%; border: #000000 1px outset;\">\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip install protobuf --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip install --upgrade google-cloud-vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to sign up for an API key. For this application, the key is a JSON file. You will create a login for Google's Cloud Services (again, they want a credit card but promise they won't charge you without asking -- you get 1,000 requests for free). You download the credentials JSON file and store it in the same folder as this notebook.\n",
    "\n",
    "We then create an \"environmental variable\" that points to the location of this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"My Project-f9004cae62d3.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the API, we will need to import two objects. One will let us make calls to the API and the other will structure image data in a way that can be analyzed by Google's algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create our API client..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now let's use the `requests` package to `get()` our image url, use the data to create an `Image` type (this time Google's `Image` object) and then apply the `label_detection()` algorithm to annotate the image.\n",
    "\n",
    "Let's have a look at the labels it finds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "\n",
    "response = get(url1)\n",
    "image = types.Image(content=response.content)\n",
    "\n",
    "# Performs label detection on the image file\n",
    "from_google = client.label_detection(image=image)\n",
    "labels = from_google.label_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the same process but when we download a file and put it in the same folder as this notebook. If it's not in the same folder, we expand the `file_name` to include the full path. Here we read the content and do what we did when we used `requests`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download an image and put it in the same folder as this notebook\n",
    "file_name = \"IMG_0254.jpg\"\n",
    "\n",
    "image_file = open(file_name,\"rb\")\n",
    "image_content = image_file.read()\n",
    "\n",
    "image = types.Image(content=image_content)\n",
    "\n",
    "# Performs label detection on the image file\n",
    "from_google = client.label_detection(image=image)\n",
    "labels = from_google.label_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A story on Twitter**\n",
    "\n",
    "Miguel Diaz-Canel is trending on Twitter (why?). Let's have a look at the images that are associated with him."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"\"\n",
    "ACCESS_TOKEN = \"\"\n",
    "ACCESS_TOKEN_SECRET = \"\"\n",
    "\n",
    "from tweepy import OAuthHandler, API\n",
    "\n",
    "# setup the authentication\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create an object we will use to communicate with the Twitter API\n",
    "api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now search Twitter for his name and store any URLs pointing to an image in a list called `image_urls`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = api.search(\"Miguel Diaz-Canel\",count=500)\n",
    "\n",
    "image_urls = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    if \"media\" in tweet.entities:\n",
    "        for m in tweet.entities[\"media\"]:\n",
    "            image_urls.append(m[\"media_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look at the label annotations for this class of image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "\n",
    "from os import environ\n",
    "environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"My Project-f9004cae62d3.json\"\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "for url in image_urls:\n",
    "\n",
    "    response = get(url)\n",
    "    image = types.Image(content=response.content)\n",
    "\n",
    "    # Performs label detection on the image file\n",
    "    from_google = client.label_detection(image=image)\n",
    "    labels = from_google.label_annotations\n",
    "    \n",
    "    print(url)\n",
    "    print(labels)\n",
    "    print(\"--\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or better yet, have the web lend us a hand and identify where this image has occured, name who it's of and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in image_urls:\n",
    "\n",
    "    response = get(url)\n",
    "    image = types.Image(content=response.content)\n",
    "\n",
    "    # Performs label detection on the image file\n",
    "    from_google = client.web_detection(image=image)\n",
    "    labels = from_google.web_detection\n",
    "    \n",
    "    print(url)\n",
    "    print(labels)\n",
    "    print(\"--\"*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
